{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "nbTranslate": {
      "displayLangs": [
        "hi"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "hi",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": false,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "308.8px",
        "left": "46px",
        "top": "194.4px",
        "width": "196.438px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "9d9b2526",
      "cell_type": "markdown",
      "source": "# Statistics Using Python Part - I by Mohammad Wasiq",
      "metadata": {}
    },
    {
      "id": "a86dd409",
      "cell_type": "markdown",
      "source": "## Statistics\nStatistics is the field of Science that deals with collection , analysis , interpretation or explanation and presentation of data . \n1. **Data Types**\n<br> We can divide the data into two parts : \n\n**A. Categoricl Data / Qualitative Data :-** The objects being studied are grouped into categories based on some\nqualitative characteristics. \n\n*The Categorical Data are further divided into two parts :* \n        \n        a. Nominal Data : A type of categorical data in which objects fall into unordered categories. \nEx -: *Gender :* Male , Female .\n<br> *Education status :* Educated, Uneducated\n<br> *Hair color :* Brown, Black, Blonde, Gray\n\n        b. Ordinal Data : A type of categoical data in which order is important.\nEx -: *Class of degree :* 1st class, 2nd, 3rd class, fail\n<br> *Level of happiness :* Very unhappy, Unhappy, OK, Happy, Very Happy\n<br> *Degree of satisfaction :* Very Unsatisfied, Somewhat Unsatisfied, Neutral, Somewhat Satisfied, Very Satisfied \n    \n**B. Non-Categorical Data / Quantitative Data :-** The objects being studied are ‘measured’ based on some quantitative trait. \n    \n*Quantitative Data are also two types :* \n           \n        a. Discrete Data : Data that can be counted.\nEx -: Number of students passing a stats exam\n<br> Number of cars sold in a day.\n\n        b. Continuous Data : Data which can be measured on scale but cann't be counted. \nEx -: Weight, Height\n\nScale of Measurement for Continuous Data \n\ni. Interval Scale : Interval scales are numeric scales in which both the order and the exact differences between the values are considered. \n<br> For example, the difference between 60 and 50 degrees is a measurable 10 degrees, as is the difference between 80 and 70 degrees.\n\n*Note :* Interval Scale data having no absolute zero. For example 0 degree doesn't mean no temperature.\n\nii. Ratio Scale : A ratio scale has all the properties of an interval scale. Ratio data on the ratio scale has measurable intervals.\n<br> For example, the difference between a height of six feet and five feet is the same as the interval between two feet and three feet. \n\n*Note :* Where the ratio scale differs from the interval scale is that it also has a meaningful zero. \n\n2. **Organization of Data**\n\nAfter the data have been collected, the main tasks a statistician must accomplish are the organization and presentation of the data. <br>\ni. *Raw Data*: Data collected in original form (before it has been organized). <br>\nii. *Class*: A Quantitative or Qualitative category in which the raw data is placed. <br>\nIt must satisfy the following conditions : \n* There is usually between 5 and 20 classes.\n* The classes must be mutually exclusive.\n* The classes must be exhaustive. <br>\niii. *Frequency Distribution*: The frequency is the number of repetition of any value. <br>\nA **frequency distribution** is the organization of raw data in tabular form, using classes and frequencies.<br>\nTypes of Frequency Distribution :<br>\na.Categorical b.Ungrouped c.Grouped",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      }
    },
    {
      "id": "c9855abf",
      "cell_type": "markdown",
      "source": "### Types of Statistics \nStatistics is mainly two types :\n1. **Descriptive Statisrics** :- Descriptive Statistics provides us with tools (Tables, Graphs, Averages, Ranges, Correlations) for organizing and summarizing the inevi-table variability in collections of actual observations or scores .\n2. **Inferential Statistics** :- The process of going from the known sample to the unknown population is called inferential statistical .",
      "metadata": {}
    },
    {
      "id": "ce9d3a8b",
      "cell_type": "markdown",
      "source": "# Descriptive Statistics- I\nQuantitative data in a mass exhibit certain general characteristics or they are differ from each other in  the following ways : \n### Descriptive Measures\n1. **Measure of Central Tendency :** Measure of tendency is calles C.T. They show a tendency to concentrate at certain values,usually somewhere in the centre of the distribution. \n\n*Some Measures of Centeral Tendency :*\n\nMeasures of Location or Central Tendency or Measure of Location gives an idea about the central \npart of the distribution.\n\nThe main objective of Measure of Central Tendency are :\n* To condense data in a single value.\n* To facilitate comparison between data \n\nRequisites of a Good Measure of Central Tendency\n<br> (i) It should be rigidly defined.\n<br> (ii) It should be simple to understand and easy to calculate.\n<br> (iii) It should be based upon all values of given data.\n<br> (iv) It should be capable of further mathematical treatment.\n<br> (v) It should have sampling stability.\n<br> (vi) It should be not be unduly affected by extreme values.\n\n---\n\n* A. **Mean / Arithmetic Mean**  \n\n* *Discrete Case :* Arithmetic Mean (A.M.) of a set of observations is their sum divided by the number of observations\n<br> Let $x_1, x_2, \\dots x_n$ are observations, then\n$$\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i$$\n\n* *Discrete or ungrouped frequency distribution :* In case of frequency distribution $X_i | f_i \\,\\, i=1,2,...,n$, where $f_i$ is the frequency of the variable $x_i$, then\n$$\\bar{x} = \\frac{1}{N} \\sum_{i=1}^n f_ix_i$$\nwhere, $N = \\sum_{i=1}^n f_i$\n\n* *Grouped or continuous frequency distribution :* In case of grouped or continuous frequency distribution, is taken as the midpoint of the corresponding class.\n$$\\bar{x} = \\frac{1}{N} \\sum_{i=1}^n f_ix_i$$\nwhere, $N = \\sum_{i=1}^n f_i$\n\n**Properties of Arithmetic Mean :**\n1. Arithmetic mean is dependent of change of origin and scale.\n2. Algebraic sum of the deviation of a set of values from their arithmetic mean is always zero.\n3.  The sum of the square of the deviation of a set of values is minimum when taken about mean\n4. **Weighted Average or Weighted Mean :** A method of computing a kind of arithmetic mean of a set of numbers in which some elements of the  set carry more importance (weight) than others.\n<br> Let there be $n$ observations $x_1,x_2,...,x_n$ and $w_1,w_2,...,w_n$ are their respective weights in the set. \n<br> Then weighted mean is calculated using the formula\n$$\\bar{x_w} = \\frac{\\sum_{i=1}^n w_ix_i}{\\sum_{i=1}^n w_i}$$\n5. **Trimmed Mean :** A trimmed mean computed by \"trimming away\" a certain percent of both the largest and the smallest set of values. For example, the $t\\%$ trimmed mean is found by eliminating the largest $t\\%$ and smallest $t\\%$ and computing the average of the remaining values. It is denoted by $\\tilde{x}$.\n\n*Note :* The trimmed mean is, in general, more insensitive to outliers (extreme values) than the sample mean. \n\n*Merits of Arithmetic Mean :*\n1. It is rigidly defined.\n2. It is easy to understand and easy to calculate.\n3. It is based upon all values of the given data.\n4. It is capable of further mathematical treatment.\n5. It is not much affected by sampling fluctuations.\n\n*Demerits of Arithmetic Mean :*\n1. It cannot be calculated if any observation is missing.\n2. It cannot be calculated for the data with open-end classes.\n3. It is affected by extreme values.\n4. It cannot be located graphically.\n5. It may be number which is not present in the data.\n6. It cannot be calculated for the data representing qualitative characteristic.\n\n---\n\n* **B. Median**\n\nMedian of a distribution is the value of the variable which divides it into two equal parts, that is the value such that the number of observations above it is equal to the number of observations below it. \n<br> The median is a positional average.\n\n*Application :*\n<br> Median is only average to be used while dealing with qualitative data which cannot be measured quantitatively but can be arranged in ascending or descending order of magnitude. \n\n* *Discrete data :* Arrange all the observations in ascending or descending order.\n* If the number of observations are **odd**, then\n$$Median = \\Bigg(\\frac{n+1}{2} \\Bigg)^{th} \\,\\, observation = \\frac{x_n+1}{2}$$\n\n* *Discrete frequency distribution :*\n\nSteps for calculating median\n* Find $N/2$, where $n=\\sum_{i=1}^n f_i$\n* Locate cumulative frequency (c.f.) just greater than $N/2$\n* The value of $x$ corresponding to that c.f. is the median \n\n\n* *Continuous frequency distribution (grouped data)*\n\nSteps for calculating median\n* Find $N/2$, where $n=\\sum_{i=1}^n f_i$\n* Locate cumulative frequency (c.f.) just greater than $N/2$\n* The class corresponding to that c.f. is the median class\n* Then use following formula to calculate median\n$$Median = l_m + \\frac{h_m}{f_m} \\Big(\\frac{N}{2}-C_p\\Big)$$\nwhere, $l_m :$ lower limit of the median class\n<br> $f_m :$ frequency of the median class\n<br> $h :$ class width\n<br> $C_p :$ c.f of the class preceeding to the median class\n\n*Merits :*\n1. It is rigidly defined.\n2. It is easy to calculate and understand\n3. It can be located merely by inspection.\n4. It is not all affected by extreme values.\n5. It can be calculated for the distributions with open-end classes.\n\n*Demerits :*\n1. In case of even number of observations median cannot be determined exactly.\n2. It is not based on all observations.\n3. It is not suitable for algebraic treatment.\n4. As compared to mean, it is affected much by fluctuations of sampling. \n\n---\n\n* **C. Mode :** Mode is the value which occurs most frequently in a set of observations.\n\n* *Discrete frequency distribution*\n\nIn case of discrete frequency distribution, mode is the value, which corresponds to maximum frequency\n\n**Note :** In any one or more of the following cases\n* If the maximum frequency is repeated.\n* If the maximum frequency occurs in the very beginning or at the end of the distribution.\n* If there are irregularities in the distribution.\n\n* *Continuous frequency distribution (Grouped data)*\n\n* Identify the modal class corresponding to the maximum frequency.\n* Calculate the mode using the following formula\n$$Mode = l + \\frac{f_m-f_p}{2\\, f_m-f_p-f_s} \\times h$$\nwhere, \n* $l :$ Lower limit of the modal class\n* $h :$ Class width\n* $f_m :$ Frequency of the modal class\n* $f_p :$ Frequency of the preceeding class \n* $f_s :$ Frequency of the successive class\n\n**Remarks :**\n1. In any one or more of the cases as defined for discrete case modal class is determined by the method of grouping.\n2. If the method of grouping gives the modal class which does not correspond to the maximum frequency or in some cases $2\\, f_m-f_p-f_s=0$, in such cases mode is obtained by using formula\n$$Mode = l + \\frac{h(f_m-f_p)}{|2\\, f_m-f_p| + |f_m-f_s|}$$\n\n*Merits :*\n1. It is easy to understand and easy to calculate.\n2. It is not affected by extreme values or sampling fluctuations.\n3. It can be located just by inspection in many cases.\n4. It is always present within data.\n5. It is applicable for both quantitative and qualitative data.\n\n*Demerits :*\n1. It is not rigidly defined.\n2. It is not based upon all values of the given data.\n3. It is not capable of further mathematical treatment.\n\n**Relationship Between Mean, Median and Mode**\n1. In positively skewed distribution, the presence of exceptionally high values affect mean more than median and mode. Therefore\n$$Mean>Median>Mode$$\n2. In negatively skewed distribution, the presence of exceptionally low values depress the mean most, followed by median and mode. Thus\n$$Mean<Median<Mode$$\n\nIn the above two situation, it can be observed that median always lies between mean and mode. \n<br> Thus, if the number of observations in any set of data is large enough to yield a fairly smooth and moderately skewed distribution, the mean, median and mode are empirically related as \n$$Mode = 3(Median) - 2(Mean)$$\n3. In the case of symmetrical distribution, the mean, median and mode coincide. That is\n$$Mean = Median = Mode$$\n\n---\n\n* **D. Geometrical Mean :** Geometric Mean (GM) of a set of observations is the $n^{th}$ root of their product.\n\n* *Discrete data*\n\nLet $x_1, x_2,...,x_n$ are $n$ observations, then\n$$GM = n_{\\sqrt{x_1 \\times x_2\\times...\\times x_n}}$$\n\nor\n$$GM= Antilog\\Big(\\frac{1}{n} \\sum_{i=1}^n log\\,x_i \\Big)$$\n\n* *Discrete frequency distribution*\n\nIn case of frequency distribution $x_i|f_i ;\\, i=1,2,...,n$ where $f_i$ is the frequency of the variable $x_i$, the geometric mean is calculated by using formula\n$$GM = n_{\\sqrt{x_1^{f_1} \\times x_2^{f_2} \\times...\\times x_n^{f_n}}}$$\nor\n$$GM= Antilog\\Big(\\frac{1}{N} \\sum_{i=1}^n f_i log\\,x_i \\Big)$$\nwhere $N=\\sum_{i=1}^n f_i$ \n\n**Uses :**\n1. To find rate of population growth and rate of interest.\n2. In construction of index number.\n\n---\n\n* **E. Harmonic Mean :** Harmonic mean of the given observations is defined as the reciprocal of the arithmetic mean of the reciprocals of the given set of observations.\n\nIf $x_1, x_2,...,x_n$ are $n$ observations, with their reciprocals $\\frac{1}{x_1}, \\frac{1}{x_2},....,\\frac{1}{x_n}$, then the Harmonic Mean(HM) is given by \n$$HM = \\frac{1}{\\frac{1}{n}\\Big(\\frac{1}{x_1}, \\frac{1}{x_2},....,\\frac{1}{x_n} \\Big)}= \\frac{n}{\\sum_{i=1}^n\\frac{1}{x_i}}$$\n\nIn this case of ungrouped frequency distribution\n$$HM = \\frac{1}{\\frac{1}{N}\\Big(\\frac{f_1}{x_1}, \\frac{f_2}{x_2},....,\\frac{f_n}{x_n} \\Big)}= \\frac{n}{\\sum_{i=1}^n\\frac{f_i}{x_i}}$$\nwhere, $N=\\sum_{i=1}^n f_i$\n\nIn the case of grouped frequency distribution $x_i, \\,\\, i=1,2,...,n$ are the mid points of the class intervals.\n\n**Note :** For computation of weighted harmonic mean $f_i$ is replaced with the weight of $i^{th}$ observation $w_i$.\n\n**Uses**\n* The Harmonic mean is often used to calculate the average of the ratios or rates. It is the most appropriate measure for ratios and rates because it equalizes the weights of each data point. For instance, the arithmetic mean places a high weight to large data points, while geometric mean gives a lower weight to the smaller data points.\n* It is most appropriate average where unit of observation (such as per day, per hour, per unit, per worker etc.) remains the same and act being performed, such as covering distance.\n\n**Relationship between AM, GM and HM**\n\nIf we compute these three averages for the same data set, then we get the relation\n$$AM>GM>HM$$ \nprovided that the observations comprising a set of data are not same.\n\nIf the set of data has the same observations, then\n$$AM=GM=HM$$\n---\n\n**Some Partition Values :**\n* **i. Quartiles :** Three points that divide the whole distribution into four equal parts are called quartiles.\n\n* *Discrete Data*\n\n* $1^{th}$ $Quartile$ $Q_1$ is the value such that $25\\%$ of the ranked data are smaller and $75\\%$ are larger.\n$$\nQ_1 = \\begin{cases} \n  \\frac{X_{n+1}}{4},  & \\text{when n is odd} \\\\\n  \\frac{1}{2} \\Big(X_{\\frac{n}{4}} + X_{\\frac{n}{4}+1} \\Big)  & \\text{when n is even}\n\\end{cases}\n$$\n\n* $2^{th}$ $Quartile$ $Q_2$ is the **Median**.\n\n* $3^{th}$ $Quartile$ $Q_3$ is the value such that $75\\%$ of the ranked data are smaller and $25\\%$ are larger.\n$$\nQ_3 = \\begin{cases} \n  \\frac{X_{3(n+1)}}{4},  & \\text{when n is odd} \\\\\n  \\frac{1}{2} \\Big(X_{\\frac{3n}{4}} + X_{\\frac{3n}{4}+1} \\Big),  & \\text{when n is even}\n\\end{cases}\n$$\n\n* *Discrete Frequency Distribution*\n\nSteps for calculating quartiles\n* Find $\\frac{jN}{4};\\,\\, j=1,2,3$ where $N=\\sum_{i=1}^n f_i$ \n* See cumulative frequency(c.f.) just greater than $\\frac{jN}{4}$\n* The value of corresponding to that c.f. is the $Q_j,\\,\\, j=1,2,3$\n\n* *Continuous Frequency Distribution (Grouped Data)*\n$$Q_j = l_q + \\frac{h}{f_q} \\Big(\\frac{jN}{4}-C_p\\Big),\\,\\, j=1,2,3$$\nwhere, $l_q :$ Lower limit of the that quartile class\n<br> $f_q :$ Frequency of the that quartile class\n<br> $h :$ Class width\n<br> $C_p :$ c.f. of the class preceeding to the quartile class.\n\n---\n\n* **ii. Deciles :** Nine points that divide the whole distribution into ten equal parts are called deciles.\n\n* *Discrete Data*\n\nSteps for calculating deciles\n* Find $\\frac{kN}{10};\\,\\, k=1,2,...,9$ where $N=\\sum_{i=1}^n f_i$ \n* See cumulative frequency(c.f.) just greater than $\\frac{kN}{10}$\n* The value of corresponding to that c.f. is the $D_k,\\,\\, k=1,2,...,9$\n\n* $5^{th}$ $Decile$ $D_5$ is the **Median**.\n\n* *Continuous Frequency Distribution (Grouped Data)*\n$$D_k = l_d + \\frac{h}{f_d} \\Big(\\frac{kN}{10}-C_p\\Big),\\,\\, k=1,2,...,9$$\nwhere, $l_d :$ Lower limit of the that decile class\n<br> $f_d :$ Frequency of the that decile class\n<br> $h :$ Class width\n<br> $C_p :$ c.f. of the class preceeding to the decile class.\n\n---\n\n* **ii. Percentiles :** Ninety-nine points that divide the whole distribution into 100 equal parts are called percentile.\n\n* *Discrete Data*\n\nSteps for calculating deciles\n* Find $\\frac{lN}{100};\\,\\, l=1,2,...,99$ where $N=\\sum_{i=1}^n f_i$ \n* See cumulative frequency(c.f.) just greater than $\\frac{lN}{100}$\n* The value of corresponding to that c.f. is the $P_l,\\,\\, l=1,2,...,99$\n\n* $50^{th}$ $Percentile$ $P_50$ is the **Median**.\n\n* *Continuous Frequency Distribution (Grouped Data)*\n$$P_l = l_p + \\frac{h}{f_p} \\Big(\\frac{lN}{100}-C_p\\Big),\\,\\, l=1,2,...,99$$\nwhere, $l_p :$ Lower limit of the that percentile class\n<br> $f_p :$ Frequency of the that percentile class\n<br> $h :$ Class width\n<br> $C_p :$ c.f. of the class preceeding to the percentile class.\n\n----\n\n2. **Measures of Variation or Dispersion :** The data vary about a measure of centeral tendency and these measures of deviation are called measures of variation or dispersion. \n\n**Characteristic for ideal measure of dispersion :**\n* (i) It should be rigidly defined.\n* (ii) It should be simple to understand and easy to calculate.\n* (iii) It should be based upon all values of given data.\n* (iv) It should be capable of further mathematical treatment.\n* (v) It should have sampling stability.\n\n**Some Measure of Dispersion :**\n* **A. Range :** The range is the *difference between the largest and smallest values* of the distribution.\n<br> Let $x_1, x_2,...,x_n$ are the set of $n$ abservations, then \n$$Range = max(x_1, x_2,...,x_n)-min(x_1, x_2,...,x_n)$$\n* One of the simplest measures of variability to calculate. \n* Depends only on extreme values and provides no information about how the remaining data is distributed. \n\n---\n\n* **B. Quartile Deviation :** Quartile Deviation or Semi Inter Quartile Range $Q$ is given by\n$$Q= \\frac{1}{2}(Q_3-Q_1)$$\nwhere $Q_1$ and $Q_3$ are the first and third quartiles of the distribution.\n\n---\n\n* **C. Mean Deviation :** \n\n* *Discrete Data*\n\nLet $x_1,x_2,...,x_n$ are $n$ observations, then \n$$MD = \\frac{1}{n}\\sum_{i=1}^n|x_i-A|$$\nwhere $A$ is generally taken as *mean, median* and *mode*.\n\n* *Discrete Frequency Distribution*\n\nIn case of frequency distribution $x_i|f_i; \\,i=1,2,...,n$, where $f_i$ is the frequency of the variables $x_i$, then \n$$MD = \\frac{1}{n}\\sum_{i=1}^n f_i|x_i-A|$$\nwhere $N=\\sum_{i=1}^nf_i$\n\n---\n\n* **D. Variance :** Variance is a measure of how data points differ from the mean.\n\n* *Discrete Case*\n\nLet $x_1,x_2,...,x_n$ are observations, then Standard Deviation generally denoted by is given by\n$$\\sigma^2= \\frac{1}{n} \\sum_{i=1}^n(x_i -\\bar{x})^2$$\n\n* *Discrete Frequency Distribution*\n\nIn case of frequency distribution $x_i|f_i; \\,i=1,2,...,n$, where $f_i$ is the frequency of the variables $x_i$, then \n$$\\sigma^2= \\frac{1}{n} \\sum_{i=1}^n f_i(x_i -\\bar{x})^2$$\n\n* It is based on all the observations; it is better measure of dispersion than mean deviation.\n* The artificiality created in the case of mean deviation is removed by squaring the .\n* It is capable of further mathematical treatment\n\n---\n\n**Sample Variance :**\n\nLet $x_1,x_2,...,x_n$ are observations taken from a population and sample size is small, then we replace the denominator $n$ by $(n-1)$ in formula of standard deviation and variance.\n\nTherefore the Sample Standard Deviation generally denoted by is given by\n$$s^2= \\frac{1}{n-1} \\sum_{i=1}^n(x_i -\\bar{x})^2$$\nBut when sample size is large, then no need to do this modification as $\\frac{n}{n-1}\\rightarrow as\\,\\, n \\rightarrow \\infty$\n\n\n* **E. Standard Deviation / Root Mean Square Deviation :** It is the square root of *variance*.\n$$SD= \\sqrt{\\sigma^2}= \\sigma$$\n\n**Note :* Standard deviation and Variance are independent of change in origin but not the scale.\n\n---\n\n**Some Useful Results :**\n\nLet $x$ is any variable and $k$ be any constant. If we denote Mean by $M$ and Variance by $V$, then \n\n**Mean :**\n1. $M(k)=k$\n2. $M(x\\mp k) = M(x) \\mp k$\n3. $m(kx)=k \\times M(x)$\n4. $M(kx \\mp c)= k \\times M(x) \\mp c$\n\nwhere $c$ is any other constant.\n\n**Variance :**\n1. $V(k)= 0$\n2. $V(x\\mp k)= V(x)$\n3. $V(kx)=k^2 \\times V(x)$\n4. $SD(kx)=k \\times SD(x)$\n\n---\n\n**Coefficient of Disperion :**\n\nSometimes we want to compare the variability of two series which differ widely in their averages or which are measured in different units, we do not only calculate the measure of dispersion but we calculate coefficient of dispersion, which are pure numbers independent of unit of measurement.\n\nThe Coefficient of Dispersion (C.D.) based on different measure of dispersion are as below:\n\n1. **CD based upon Range :** $\\frac{A-B}{A+B}$\n\nwhere $A$ is the largest value and $B$ is the smallest value in the series.\n\n2. **CD based upon Quartile Deviation :** $\\frac{Q_3-Q_1}{Q_3+Q_1}$\n\nwhere $Q_1$ and $Q_3$ are first and third quartiles respectively.\n\n3. **CD based upon Mean Deviation :** $\\frac{M.D.}{\\bar{x}}$\n\n4. **CD based upon SD :** $\\frac{\\sigma}{\\bar{x}}$\n\n5. **Coefficient of Variation / C.V. :** 100 times the coefficient of dispersion based on standard deviation (S.D.) is called Coefficient of Variation, that is $\\frac{\\sigma}{\\bar{x}} \\times 100$\n\n---\n\n3. **Measures of Skewness :** The data in a frequency distribution may fall into symmetrical o asymmertical patterns. The measures of direction and degree of symmetry are called measure of skewness.\n\nSkewness Means :Lack of Symmetry\n\n*Some Measure of Skewness*\n1. $S_k=M-M_d$\n2. $S_k=M-M_0$\n3. $Q_1+Q_3-2Q_2 \\quad | \\quad Q_1+Q_3-2M_d$\n4. $\\frac{M-M_0}{\\sigma}$\n5. $\\frac{3(M-M_0)}{\\sigma}$\n\nI.*Prof. Karl Pearson's Coefficient of Skewness* : $\\frac{(M-M_0)}{\\sigma}, \\,\\, limit\\,\\, of\\,\\, S_k \\pm3$\n\nII.*Prof. Bowley's Coefficient of Skewness* : $\\frac{(Q_1+Q_3-2Q_2)}{Q_3-Q_1}$\n\nIII.*Based upon Moments,coefficient of skewness* : $S_k=\\frac{\\sqrt{\\beta_1}(\\beta_2+3)}{2(5\\beta_2-6\\beta_1-9)}$\n\n---\n\n4. **Measure of Kurtosis :** Polygons of frequency distributions exhibit flatness or peakedness of the frequency curves. The measures of peakedness or flatness of the frequency curves are called measures of kurtosis.\n$$\\beta_1=\\frac{\\mu_{2}^3}{\\mu_{3}^2} \\quad , \\gamma_1= {\\sqrt{\\beta_1}}$$\n\n$$\\beta_2=\\frac{\\mu_4}{\\mu_{2}^2} \\quad , \\gamma_1= \\beta_1-3$$\n\n* If $\\beta_2<3,\\quad \\Rightarrow \\gamma_2<3$  Curve is $Platykurtic$\n* If $\\beta_2=3,\\quad \\Rightarrow \\gamma_2=3$  Curve is $Mesokurtic/Normal$\n* If $\\beta_2>3,\\quad \\Rightarrow \\gamma_2>3$  Curve is $Leptokurtic$\n\n---",
      "metadata": {}
    },
    {
      "id": "f0c45322",
      "cell_type": "code",
      "source": "# Import the Statistics Librarry\nimport statistics as stat",
      "metadata": {},
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "1a6b03a5",
      "cell_type": "code",
      "source": "# Creating a Vector\nx = [60,83,83,91,100] ",
      "metadata": {},
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "5ea18c88",
      "cell_type": "code",
      "source": "# To Calculate mean of x\nstat.mean(x) ",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "83.4"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 3
    },
    {
      "id": "dc4921e4",
      "cell_type": "code",
      "source": "# To Calculate mean of x\nstat.mean(x) ",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "83.4"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 4
    },
    {
      "id": "09ed4eee",
      "cell_type": "code",
      "source": "# To calculate mode of x\nstat.mode(x)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 5
    },
    {
      "id": "933ea584",
      "cell_type": "code",
      "source": "# To calculate standard deviation of x\nstat.stdev(x) ",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14.842506526863986"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "760e5220",
      "cell_type": "code",
      "source": "# To calculate vaiance of x\nstat.variance(x) ",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "220.3"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 8
    },
    {
      "id": "f6f2307f",
      "cell_type": "code",
      "source": "import math as m\nm.sqrt(stat.variance(x))",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14.842506526863986"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 10
    },
    {
      "id": "511c2f39",
      "cell_type": "code",
      "source": "# To calculate quartile of x\nstat.quantiles(x) ",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[71.5, 83.0, 95.5]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 11
    },
    {
      "id": "e6145353",
      "cell_type": "code",
      "source": "# To Calculate the minimum value of x\nmin(x) ",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 12
    },
    {
      "id": "5472ad73",
      "cell_type": "code",
      "source": "# to Calculate the maximum value of x\nmax(x)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 13
    },
    {
      "id": "fb4c39f6",
      "cell_type": "code",
      "source": "# To calculate geometric mean of x\nstat.geometric_mean(x) ",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "82.23747464222964"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 14
    },
    {
      "id": "e4da5c68",
      "cell_type": "code",
      "source": "# To calculate harmonic mean of x\nstat.harmonic_mean(x)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "80.9689545753409"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 15
    },
    {
      "id": "5abc9b8d",
      "cell_type": "code",
      "source": "# To Calculate the Coefficient of dispersion based on Range\ncdr=(max(x)-min(x))/(max(x)+min(x))\ncdr",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 16
    },
    {
      "id": "5cbc1fdd",
      "cell_type": "code",
      "source": "# To Calculate the Coefficient of dispersion based on Quartile\ncdq = (99.5-71.5)/(99.5+71.5)\ncdq",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.16374269005847952"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 17
    },
    {
      "id": "7bf113cc",
      "cell_type": "code",
      "source": "# To Calculate the Coefficient of dispersion based on Standard Deviation\ncdsd = stat.stdev(x)/stat.mean(x)\ncdsd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1779677041590406"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 20
    },
    {
      "id": "98b7d0cd",
      "cell_type": "code",
      "source": "# To Calculate the Coefficient of Variation\ncv = cdsd*100 ; cv",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17.79677041590406"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 21
    },
    {
      "id": "270ab27f",
      "cell_type": "code",
      "source": "# To Calculate the Measure of Skewness\nfrom scipy.stats import skew\nsk = skew(x)  ; sk",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-0.6667369269731003"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 22
    },
    {
      "id": "03b99cd6",
      "cell_type": "code",
      "source": "# To Calculate the Skewness by Median\nsk1 = stat.mean(x)-stat.median(x) ; sk1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4000000000000057"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 24
    },
    {
      "id": "944b5b66",
      "cell_type": "code",
      "source": "# To Calculate the Skewness by Mode\nsk2 = stat.mean(x)-stat.mode(x) ; sk2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4000000000000057"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 25
    },
    {
      "id": "950556b0",
      "cell_type": "code",
      "source": "# To Calculate the Skewness by Quartile\nsk3 = (71.5+95.5-2*83.0) ; sk3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 26
    },
    {
      "id": "0497cf47",
      "cell_type": "code",
      "source": "# Skewness by mode and sd\nsk4 = (stat.mean(x)-stat.mode(x))/(stat.stdev(x))\nsk4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.026949626013371215"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 27
    },
    {
      "id": "cc6b9b71",
      "cell_type": "code",
      "source": "# To Calculate the Skewness by median and sd\n# Prof. Karl Pearson's Coefficient of Skewness \n\nsk5 = 3*(stat.mean(x)-stat.median(x))/(stat.stdev(x))\nsk5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.08084887804011363"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 28
    },
    {
      "id": "b451773e",
      "cell_type": "code",
      "source": "# To Calculate the Skewness\n# Prof. Bowley's Coefficient of Skewness \n\nsk6 = (71.5+95.5-2*83.0)/(95.5-71.5)\nsk6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.041666666666666664"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 29
    },
    {
      "id": "ea98a3ff",
      "cell_type": "code",
      "source": "# To Calculate the Measure of Kurtosis\nfrom scipy.stats import kurtosis \nkts = kurtosis(x)  ; kts # This graph is platykurtic",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-0.5590149733918302"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 30
    },
    {
      "id": "adadabf6",
      "cell_type": "markdown",
      "source": "## Correlation\n1. **Simple Correlation :-**\nCorrelation measures how variables are related. \n\nThe correlation coefficient is used to quantify the strength and the direction of the linear relationship between two variables and usually denoted by r . The linear correlation coefficient is sometimes referred to as the *Pearson product moment correlation coefficient* in honour of its developer Professor Karl Pearson.\n\nPearson’s correlation coefficient, used when\n* a. Data is quantitative.\n* b. Distribution of variables is normal.\n* c. Linear relationship between two variables.\n* d. All observations should be independent .\n$$r = (\\rho) = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y},\\quad -1< \\rho < +1$$\nwhere, $Cov(X,Y)=\\frac{\\sum_{i\\neq j=1}^n (X_i-\\bar{X})(Y_j-\\bar{Y})}{n}$\n\n**Remarks :**\n<br> The value of $r$ is such that $-1 \\le r \\le +1$.The *+* and *-* signs are used positive linear correlations and negative correlations, respectively. <br>\n* i. **Positive Correlation :** If  two variables X and Y deviate in same direction, that is the increase/decrease in one results in corresponding increase/decrease in other, the correlation is said to be positive. *For example height and weight of group of persons.*\n* ii. **Negative Correlation :** If two variables X and Y deviate in opposite direction, that is the increase/decrease in one results in corresponding decrease/increase in other, the correlation is said to be negative. *For example pressure and volume of gas*.\n* iii. **No Correlation :** The two variables X and Y is said to be uncorrelated if and increase/decrease in one results in no change in other. *For example weight and IQ.*\n* iv. **Perfect Correlation :** The correlation is said to be perfect if the deviation in one variable followed by the corresponding proportional deviation in other. The value $r=+1$ indicates perfect positive correlation whereas $r=-1$ means perfect negative correlation.\n\nThe correlation coefficient r is a dimensionless quantity; that means it does not depend on\nthe units employed .\n\n**Note that :**\n* If r = 0 this means no association or correlation between the two variables.\n* If $0 <r< 0.25 | -0.25 <r< 0$ : weak **positive | negative correlation.**\n* If $0.25 <r< 0.75 | -0.75 <r< -0.25$: intermediate **positive | negative correlation.**\n* If $0.75 <r< 1 | -1 <r< -0.75$: strong **positive | negative correlation.**\n* If $r=+1 | r=-1$: perfect **positive/negative correlation.**\n\n**Spearman's rank correlation coefficient :**\n\nSpearman's rank correlation coefficient, named after Charles Spearman, is a non-parametric measure of correlation. Unlike the Pearson product-moment correlation coefficient, it does not require the assumption that the relationship between the variables is linear, nor does it require the variables to be measured on interval scales; it can be used for variables measured at the ordinal level.\n$$r_{s}=1-\\frac{6\\sum_{i=1}^n d_{i}^2}{n(n^2-1)}$$ \nwhere $n =$ no. of obs. in each series.\n\n---\n\n2. **Partial Correlation :**\n\nPartial correlation analysis involves studying the linear relationship between two variables after excluding the effect of one or more independent factors. \n<br>For example suppose that there are three variables Sale$(X_1)$,Price$(X_2)$ and Production $(X_3)$ and one wants to find the linear relationship between Sale$(X_1)$ ,Price$(X_2)$ after controlling the Production$(X_3)$ .\n\n**coefficient of Partial Correlation :-** Partial correlation between $X_1$ and $X_2$ after controlling the effect of $X_3$ and usually denoted by $r_{12.3}$ is given as :\n$$r_{12.3}=\\frac{r_{12}-r_{13}r_{23}}{\\sqrt{(1-r_{13}^2)(1-r_{23}^2)}}$$\n\nSimilarly , \n$$r_{13.2}=\\frac{r_{13}-r_{12}r_{23}}{\\sqrt{(1-r_{12}^2)(1-r_{23}^2)}}$ , as $r_{23}=r_{32}$$\n\nand\n$$r_{23.1}=\\frac{r_{23}-r_{12}r_{13}}{\\sqrt{(1-r_{12}^2)(1-r_{13}^2)}}$$\n\n----\n\n3. **Multiple Correlation :** \nSometimes we find interrelationship between many variables and value of one variable may be influenced by many others. \n<br>For example the yield of crop per hectare, say $(X_1)$ depends upon quality of seed$(X_2)$,fertility of soil $(X_3)$,fertilizer used$(X_4)$, irrigation facilities$(X_5)$, weather condition$(X_6)$ and so on. When someone is interested in studying joint effect of variables upon a variable not included in that group, our study is that of multiple correlation and multiple linear regression analysis.\n\n**Coefficient of Multiple Correlations :** Consider a trivariate distribution in which each of the variable $X_1,X_2,and X_3$ has $n$ observations.\n\nThe  multiple correlation coefficient of $X_1, X_2, \\,\\,and\\,\\, X_3$ , usually denoted by $R_{1.23}$ is given by :\n$$R_{1.23}^2=\\frac{r_{12}^2+r_{13}^2-2*r_{12}r_{13}r_{23}}{1-r_{23}^2}$$\nThis is also called simple correlation between $X_1$ and joint effect of $X_2$ and $X_3$ on $X_1$.\n\nThe multiple correlation coefficient of $X_2$ and $X_1$ on $X_3$ is given as :\n$$R_{2.13}^2=\\frac{r_{12}^2+r_{23}^2-2*r_{12}r_{13}r_{23}}{1-r_{13}^2}$$\n\nand the multiple correlation coefficient of $X_3$ and $X_1$ on $X_2$ is\n$$R_{3.12}^2=\\frac{r_{13}^2+r_{23}^2-2*r_{12}r_{13}r_{23}}{1-r_{12}^2}$$\n\n$r_{ij}=r_{ji,i\\neq j}$ is the correlation between $X_i$ and $X_j$ .\n<br> **To see the correlation between variables by graphs , we use _Scatter plot_ and _Line chart_**\n\n---",
      "metadata": {}
    },
    {
      "id": "1963a901",
      "cell_type": "code",
      "source": "# To Calculate the Correlation between two variables \nx1 = [4,3,5,6,7,7,8,9,3,5]\nx2 = [5,3,5,6,7,8,4,3,6,8]\nimport pingouin as pg\npg.corr(x1,x2)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n</th>\n",
              "      <th>r</th>\n",
              "      <th>CI95%</th>\n",
              "      <th>r2</th>\n",
              "      <th>adj_r2</th>\n",
              "      <th>p-val</th>\n",
              "      <th>BF10</th>\n",
              "      <th>power</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pearson</th>\n",
              "      <td>10</td>\n",
              "      <td>-0.044</td>\n",
              "      <td>[-0.66, 0.6]</td>\n",
              "      <td>0.002</td>\n",
              "      <td>-0.283</td>\n",
              "      <td>0.90393</td>\n",
              "      <td>0.389</td>\n",
              "      <td>0.051</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          n      r         CI95%     r2  adj_r2    p-val   BF10  power\n",
              "pearson  10 -0.044  [-0.66, 0.6]  0.002  -0.283  0.90393  0.389  0.051"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 31
    },
    {
      "id": "2cd57253",
      "cell_type": "code",
      "source": "# To Calculate the correlation coefficient \nnp.corrcoef(x1, x2)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.04400265],\n",
              "       [-0.04400265,  1.        ]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 33
    },
    {
      "id": "a3a9bbb8",
      "cell_type": "code",
      "source": "# To Calculate the  Karl Pearson's Correlation \nfrom scipy.stats import pearsonr\nkpc = pearsonr(x1, x2)\nkpc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(-0.04400265197307414, 0.903930356086283)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 32
    },
    {
      "id": "47a66f17",
      "cell_type": "code",
      "source": "# To Calculate the Spearman's rank correlation coefficient\nfrom scipy.stats import spearmanr\nsrcc = spearmanr(x1, x2)\nsrcc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SpearmanrResult(correlation=-0.021671930489041497, pvalue=0.9526149117123045)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 34
    },
    {
      "id": "dd5a6e72",
      "cell_type": "code",
      "source": "#  To Calculate the Partial Correlation \n# data: name of the dataframe\n# x, y: names of columns in the dataframe\n# covar: the name of the covariate column in the\n\nimport pandas as pd\ndf = pd.DataFrame({'CurrentGrade':  [82, 88, 75, 74, 93, 97, 83, 90, 90, 80],\n        'Hours': [4, 3, 6, 5, 4, 5, 8, 7, 4, 6],\n        'ExamScore': [88, 85, 76, 70, 92, 94, 89, 85, 90, 93]})\ndf\n\n# find partial correlation between \n# hours and exam score while controlling for grade\npg.partial_corr(df, x='Hours' ,\n                y='ExamScore', covar= 'CurrentGrade')",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n</th>\n",
              "      <th>r</th>\n",
              "      <th>CI95%</th>\n",
              "      <th>r2</th>\n",
              "      <th>adj_r2</th>\n",
              "      <th>p-val</th>\n",
              "      <th>BF10</th>\n",
              "      <th>power</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pearson</th>\n",
              "      <td>10</td>\n",
              "      <td>0.191</td>\n",
              "      <td>[-0.5, 0.73]</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-0.239</td>\n",
              "      <td>0.597831</td>\n",
              "      <td>0.438</td>\n",
              "      <td>0.082</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          n      r         CI95%     r2  adj_r2     p-val   BF10  power\n",
              "pearson  10  0.191  [-0.5, 0.73]  0.036  -0.239  0.597831  0.438  0.082"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 36
    },
    {
      "id": "71870936",
      "cell_type": "code",
      "source": "# To Calculate the all pairwise partial correlations, rounded to three decimal places\ndf.pcorr().round(3)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CurrentGrade</th>\n",
              "      <th>Hours</th>\n",
              "      <th>ExamScore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CurrentGrade</th>\n",
              "      <td>1.000</td>\n",
              "      <td>-0.311</td>\n",
              "      <td>0.736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hours</th>\n",
              "      <td>-0.311</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExamScore</th>\n",
              "      <td>0.736</td>\n",
              "      <td>0.191</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              CurrentGrade  Hours  ExamScore\n",
              "CurrentGrade         1.000 -0.311      0.736\n",
              "Hours               -0.311  1.000      0.191\n",
              "ExamScore            0.736  0.191      1.000"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 37
    },
    {
      "id": "9496c86c",
      "cell_type": "code",
      "source": "# To Calculate the five number theory\ndf.describe()",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CurrentGrade</th>\n",
              "      <th>Hours</th>\n",
              "      <th>ExamScore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>85.200000</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>86.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.641989</td>\n",
              "      <td>1.549193</td>\n",
              "      <td>7.714345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>74.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>70.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>80.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>85.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>85.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>88.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>91.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>97.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>94.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       CurrentGrade      Hours  ExamScore\n",
              "count     10.000000  10.000000  10.000000\n",
              "mean      85.200000   5.200000  86.200000\n",
              "std        7.641989   1.549193   7.714345\n",
              "min       74.000000   3.000000  70.000000\n",
              "25%       80.500000   4.000000  85.000000\n",
              "50%       85.500000   5.000000  88.500000\n",
              "75%       90.000000   6.000000  91.500000\n",
              "max       97.000000   8.000000  94.000000"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 38
    },
    {
      "id": "f01caee0",
      "cell_type": "markdown",
      "source": "### Covariance\ncovariance is a measure of the relationship between two random variables. The metric evaluates how much – to what extent – the variables change together. In other words,it is essentially a measure of the variance between two variables. However, the metric does not assess the dependency between variables.\n\nUnlike the correlation coefficient, covariance is measured in units. The units are computed by multiplying the units of the two variables. The variance can take any positive or negative values. The values are interpreted as follows:\n* i. **Positive Covariance :-** Positive Covaiance indicates that two variables tend to move in same direction .\n* ii. **Negative Covariance :-** Negative Covariance revels that two variables tends to move in inverse direction.\n$$Cov(X,Y) = \\frac{\\sum_{i\\neq j=1}^n (X_i-\\bar{X})(Y_j-\\bar{Y})}{n}$$\n\n__Difference between Covariance and Correlation__ \n<br>Covariance and correlation both primarily assess the relationship between variables. The closest analogy to the relationship between them is the relationship between the variance and standard deviation.\n\n**Covariance** measures the total variation of two random variables from their expected values. Using covariance, we can only gauge the direction of the relationship (whether the variables tend to move in tandem or show an inverse relationship). However, it does not indicate the strength of the relationship, nor the dependency between the variables.\n<br>On the other hand, **Correlation** measures the strength of the relationship between variables. Correlation is the scaled measure of covariance. It is dimensionless. In other words, the correlation coefficient is always a pure value and not measured in any units.\n\n$Correlation = (\\rho)=\\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y},\\quad -1< \\rho < +1$",
      "metadata": {}
    },
    {
      "id": "136b5f2e",
      "cell_type": "code",
      "source": "# To Calculate the Covariance\nfrom numpy import cov\ncov = cov(df['CurrentGrade'],df['ExamScore'])\ncov",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[58.4       , 42.73333333],\n",
              "       [42.73333333, 59.51111111]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 39
    },
    {
      "id": "38d82025-6d81-4d96-9796-7c71d769533c",
      "cell_type": "markdown",
      "source": "<center><h1> Thank You </h1></center>",
      "metadata": {}
    },
    {
      "id": "0aa8bf67",
      "cell_type": "markdown",
      "source": "## Discrete Probability Distribution\n### Binomial Distribution \nIf we repeat Bernoulli tial n times and let _x_ be the  the number of successes in n trials and each trial has constant probability of success (p). Then the probability distribution of number of successes (X) is called Binomial distribution.\n\nIn the definition above, we notice that the following conditions need to be satisfied for a binomial experiment : \n* i. There are a fixed number of n trials carried out.\n* ii.The outcome of a given trial is either a “success” or “failure”.\n* iii.The probability of success (p) remains constant from trial to trial.\n* iv.The trials are independent, and the outcome of a trial is not affected by the outcome of any other trial.\n\nWe denote the Binomial Distribution as:\n$X \\sim B(x,n,p)$\n\nThe PMF or Probability Distribution is given by-\n$$P(X=x)={n \\choose x}p^{x}(1-p)^{n-x} ;\\quad x=0,1,2 \\cdots n ; q=(1-p)$$\n\nBinomial Distribution has :\n* mean $\\mu=np$ \n* variance $\\sigma^2=np(1-p)$ \n* mgf is $M_{x}(t)=((1-p)+pe^t)^n$\n\nRecursive Relation for Probability :\n$$P(X=x+1)=\\frac{p}{q}\\frac{(n-x)}{x+1}P(X=x)$$\n* For *small p* and *large n*, the binomial distribution *skewed right*.\n* For *p=0.5* and *small n*, the binomial distribution *symmetry*.\n* For *large p* and *small n*, the binomial distribution *skewed left*.",
      "metadata": {}
    },
    {
      "id": "e1926796",
      "cell_type": "markdown",
      "source": "* 10 binomial Random Sample of n=10 , prob.=0.6",
      "metadata": {}
    },
    {
      "id": "724832ca",
      "cell_type": "code",
      "source": "[n,p,size] = [10,0.6,10]\nrbinom = np.random.binomial(n,p,size) ;rbinom",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([6, 7, 3, 4, 9, 4, 6, 6, 4, 7])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 40
    },
    {
      "id": "7ac69edd",
      "cell_type": "markdown",
      "source": "* Ten 10 trials for coin toss generate 10 data points",
      "metadata": {}
    },
    {
      "id": "722253e0",
      "cell_type": "code",
      "source": "from numpy import random as r\nb1 = r.binomial(n=10,p=0.5) ; b1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 41
    },
    {
      "id": "81941f3c",
      "cell_type": "markdown",
      "source": "* Simulate the 10 random no. with prob.=0.5",
      "metadata": {}
    },
    {
      "id": "799c526a",
      "cell_type": "code",
      "source": "b11 = r.binomial(n=10,p=0.5,size=10) ; b11",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 1, 7, 4, 2, 3, 6, 6, 7, 8])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 42
    },
    {
      "id": "ac06e167",
      "cell_type": "code",
      "source": "# Mean of binomial n=10,p=0.5\nnp.mean(b11)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.6"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 43
    },
    {
      "id": "0296dc06",
      "cell_type": "code",
      "source": "# SD of b11\nnp.std(b11)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.3748684174075834"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 44
    },
    {
      "id": "a70691b3",
      "cell_type": "markdown",
      "source": "**PMF of Binomial Distribution**\n* The chance of 3 sixes in 10 rolls of a die . Find its prob.\n\n`stat.binom(x=3, n=10, p=1/6)`",
      "metadata": {}
    },
    {
      "id": "44a64ada",
      "cell_type": "code",
      "source": "from scipy import stats \nbpmf = stats.binom.pmf(3, 10, 1/6) ; bpmf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.15504535957425197"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 45
    },
    {
      "id": "13b5d67a",
      "cell_type": "code",
      "source": "# To calculate the P(2<=X<=4)=P(X=2)+P(X=3)+P(X=4)\np24 = stats.binom.pmf([2,3,4], 10, 1/6) ;p24",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.29071005, 0.15504536, 0.05426588])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 46
    },
    {
      "id": "af0ce2f4",
      "cell_type": "code",
      "source": "sum(p24)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5000212846269625"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 47
    },
    {
      "id": "087a1d7a",
      "cell_type": "code",
      "source": "# To calculate the P(X>3)=1-P(X<=3)\np3 = 1-sum(stats.binom.pmf([1,2,3], 10, 1/6)) ;p3\nround(p3,3)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.231"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 48
    },
    {
      "id": "c7d1bc68",
      "cell_type": "code",
      "source": "# Random Number Generation\nbr = stats.binom.rvs(n=10,p=0.5,size=10) ; br",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 5, 7, 4, 5, 8, 4, 6, 9, 5])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 49
    },
    {
      "id": "b4643ece",
      "cell_type": "code",
      "source": "# CDF of binomial distribution\nbcdf = stats.binom.cdf(3,10,0.5) ; bcdf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.17187499999999994"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 50
    },
    {
      "id": "3f686775",
      "cell_type": "markdown",
      "source": "### Poisson Distribution\nThe Poisson distribution is used to model the number of events occurring within a given time interval.\n\nPoisson distribution occurs when there are events which do not occur as outcomes of a definite number of trials (unlike that in binomial) of an experiment but occur at random points of time and space, wherein our interest lies only in the number of occurrences of the event, not its non-occurrences.\n\nHere are some situations where we can use Poisson distribution\n* i. Number of WhatsApp messages received on a cell phone in some unit of time.\n* ii. Number of calls received on your mobile in some unit of time.\n* iii. Number of aircraft accidents in some unit of time.\n* iv. Number of items failed in manufacturing process during given time period\n* v. Number of defective items in a box of 100 items.\n\n*We denote Poisson Distribution as :*\n\n$X \\sim P(\\lambda)$\n<br>The PMF of Poisson Distribution is written as :\n$$P(X=x)=\\frac{e^{\\lambda}\\lambda^{x}}{x!} , \\quad x=0,1,2,3,\\cdots,\\infty$$\nPoisson Distribution has : \n* same mean and vaiance i.e. $\\lambda=np$ \n* mgf $M_{x}(t)=e^{\\lambda(e^{t}-1)}$\n\nRecurrence relation for probability:\n$$P(X=x+1)=\\frac{\\lambda}{(x+1)}P(X=x)$$\nIf in the pmf of Binomial Distribution $n\\rightarrow \\infty \\quad and \\quad p\\rightarrow 0$ then it's convert into Poisson Distribution . ",
      "metadata": {}
    },
    {
      "id": "597da9d3",
      "cell_type": "code",
      "source": "from numpy import random as r\nfrom scipy import stats\nimport statistics as stat",
      "metadata": {},
      "outputs": [],
      "execution_count": 51
    },
    {
      "id": "2de32843",
      "cell_type": "markdown",
      "source": "* 10 Poisson Random Sample of mean=3",
      "metadata": {}
    },
    {
      "id": "c80969e9",
      "cell_type": "code",
      "source": "[mean,size] = [3, 10]\nrpois = np.random.poisson(mean,size) ;rpois",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 2, 1, 3, 2, 1, 3, 1, 5, 0])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 52
    },
    {
      "id": "c16d3c0b",
      "cell_type": "code",
      "source": "# Generate a random 1x10 distribution for occurence 2:\np = r.poisson(lam=2, size=10) ;p",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 3, 4, 4, 2, 1, 1, 4, 0, 1])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 53
    },
    {
      "id": "43ddfb45",
      "cell_type": "code",
      "source": "# Generate random values from Poisson distribution \n# with mean=3 and sample size=10\np1 = stats.poisson.rvs(mu=3, size=10) ;p1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 2, 1, 3, 3, 8, 2, 0, 3, 2])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 54
    },
    {
      "id": "77f53226",
      "cell_type": "markdown",
      "source": "If X be the number of calls received at your cell phone with mean number of calls \n\n2. Find the probability that on a randomly selected occasion there will be \n* i) None \n* ii) One\n* iii) Atleast one \n* iv) Atmost one",
      "metadata": {}
    },
    {
      "id": "6c046648",
      "cell_type": "code",
      "source": "# (i) None = P(X=0)\npi = stats.poisson.pmf(0, 2) ;pi",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1353352832366127"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 55
    },
    {
      "id": "4c259411",
      "cell_type": "code",
      "source": "# (ii) One = P(X=1)\npii = stats.poisson.pmf(1, 2) ; pii",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2706705664732254"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 56
    },
    {
      "id": "747ede23",
      "cell_type": "code",
      "source": "# (iii) At least one=P(X>=1)=1-P(X<1)=1-P(X=0)\npiii = 1-stats.poisson.pmf(0, 2) ; piii",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8646647167633873"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 57
    },
    {
      "id": "138071c2",
      "cell_type": "markdown",
      "source": "* A certain store sells seven footballs per day on average.  What is the probability that this store sells four or less footballs in a given day ?\n\n**mean=7 , P(X<=4) = ?**",
      "metadata": {}
    },
    {
      "id": "4dcd941c",
      "cell_type": "code",
      "source": "pcdf = stats.poisson.cdf(4, 7) ; pcdf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.17299160788207146"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 58
    },
    {
      "id": "87f8bc6f",
      "cell_type": "code",
      "source": "# To calculate the mean \nstat.mean(p)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 59
    },
    {
      "id": "9e857009",
      "cell_type": "code",
      "source": "# To Calculate the variance \nstat.variance(p)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 60
    },
    {
      "id": "bacfa9c3",
      "cell_type": "markdown",
      "source": "### Geometric Distribution \n*Conditions :*\n* i.Repetition of Bernoulli trial unit first success.\n* ii.Each trial has a constant probability of success (say p).\n* iii.Repeated trials are independent.\n\nWe denote the Geometric Distribution as :\n\n$X \\sim Geo(p)$\n\nThe PMF of Geometric Distribution is written as :\n$$F(x)=P(X=x)=p(1-p)^x ,\\quad x=0,1,2\\cdots \\infty$$\n\nIt's takes : \n* mean $\\mu=\\frac{1}{p}$ \n* variance $\\sigma^2=\\frac{(1-p)}{p^2}$ \n* mgf $M_{x}(t)=\\frac{pe^t}{1-(1-p)e^t}$\n\n*Memoryless Property of Geometric Distribution :*\n\nSuppose that an event has not occurred during the first $s$ repetitions. Then probability that it will not occur during the next $t$ repetitions, is the same as the probability that it will not occur during the first $t$ repetition. \n<br> In other words, the information of no success is forgotten so far as subsequent calculations are concerned.\n\nSuppose that *X* has a geometric distribution, then for any two positive integers *s* and *t*, then\n<br>$P(X \\geq s+t|X>s)=P(X \\geq t)$ , coverse is also *TRUE* .\n\n**Note :** *Geometric Distribution is only discrete distribution which has memoryless property.*",
      "metadata": {}
    },
    {
      "id": "40d653e9",
      "cell_type": "code",
      "source": "# 10 Geometric Random Sample of  prob.=0.6\n[p, size] = [0.7, 10]\nrgeom = np.random.geometric(p, size) ;rgeom",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 1, 1, 3, 1, 1, 1, 2, 4, 1])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 61
    },
    {
      "id": "58ac8883",
      "cell_type": "code",
      "source": "# Generate a random 1x10 distribution for probability 0.6\ng = r.geometric(0.6, 10) ;g",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 1, 2, 1, 4, 1, 2, 1, 8])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 62
    },
    {
      "id": "c823b252",
      "cell_type": "code",
      "source": "# Generate random values from Geometric distribution \n# with prob.=0.6 and sample size=10\ng1 = stats.geom.rvs(p=0.6, size=10) ;g1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 2, 5, 3, 1, 3, 1, 2, 2])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 63
    },
    {
      "id": "aad5daa2",
      "cell_type": "code",
      "source": "# To calculate mean\nnp.mean(g)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.3"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 64
    },
    {
      "id": "bc5ea815",
      "cell_type": "code",
      "source": "# Tp calculate variance \nnp.var(g)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.41"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 65
    },
    {
      "id": "e99118dd",
      "cell_type": "markdown",
      "source": "**Probability that a missile hits a target is 0.5.\n<br> Find out the probability that**\n* i) Fourth missile will hit the target.\n* ii) Atleast 3 missiles needed to hit the target .\n* iii) Atmost 3 missiles required to hit the target.",
      "metadata": {}
    },
    {
      "id": "b3e01c40",
      "cell_type": "code",
      "source": "# i) p=0.5 , P(X=4) ; k=x\n\ngi = stats.geom.pmf(k=4, p=0.5) ; gi",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0625"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 66
    },
    {
      "id": "296d84db",
      "cell_type": "code",
      "source": "# ii) Atleast 3 missiles needed to hit the target . \n# P(X>=3) = 1-P(X<3) = 1-[P(X=0) + P(X=1) + P(X=2)]\n\ngii = 1-sum(stats.geom.pmf([0,1,2], 0.5)) ;gii",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 67
    },
    {
      "id": "76e3b784",
      "cell_type": "code",
      "source": "# iii) Atmost 3 missiles required to hit the target.\n# P(X<=3) = P(X=0) + P(X=1) + P(X=2) + P(X=3)\n\ngiii = sum(stats.geom.pmf([0,1,2,3], 0.5)) ;giii",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.875"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 68
    },
    {
      "id": "0533dd32",
      "cell_type": "code",
      "source": "# CDF\ngiv = stats.geom.cdf(3, 0.5) ;giv",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.875"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 69
    },
    {
      "id": "251c6180",
      "cell_type": "code",
      "source": "# Percent point function (inverse of cdf — percentiles).\n# ppf(q, p, loc=0)\n\nstats.geom.ppf(0.4, 0.6)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 70
    },
    {
      "id": "3c5f817c",
      "cell_type": "code",
      "source": "# Mean(‘m’), variance(‘v’), skew(‘s’), \n# and/or kurtosis(‘k’).\n# stats(p, loc=0, moments=’mv’)\n\nstats.geom.stats(0.6, moments='mv')",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(1.66666667), array(1.11111111))"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 71
    },
    {
      "id": "3812768e",
      "cell_type": "code",
      "source": "# Median of the distribution\n# median(p, loc=0)\nstats.geom.median(0.6)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 72
    },
    {
      "id": "8b368167",
      "cell_type": "code",
      "source": "# Mean of the distribution.\n# mean(p, loc=0)\nstats.geom.mean(0.6)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.6666666666666667"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 73
    },
    {
      "id": "3c95d0bc",
      "cell_type": "code",
      "source": "# Variance of the distribution.\n# var(p, loc=0)\nstats.geom.var(0.6)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.1111111111111114"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 74
    },
    {
      "id": "4c70a909",
      "cell_type": "code",
      "source": "# Standard deviation of the distribution.\n# std(p, loc=0)\nstats.geom.std(0.6)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0540925533894598"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 75
    },
    {
      "id": "a03bdf3a",
      "cell_type": "code",
      "source": "# Moments\nstats.geom.moment(0,0.6)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 76
    },
    {
      "id": "a0ef76c4",
      "cell_type": "markdown",
      "source": "### Negative-Binomial Distribution\n**Conditions :**\n* i.Repetition of Bernoulli trial unit $r^{th}$ success.\n* ii.Each trial has a constant probability of success (say p).\n* iii.Repeated trials are independent.\n\nWe denote the pmf of Negative Binomial Distribution as :\n<br> $X \\sim BIN(r,p)$\n\nSuppose $X=x$, that means at $x^th$ trial there is a success and there are $(r-1)$ successes in $(x-1)$ previous repetitions. If probability of success at each trial is $p$, then probability distribution of $X$ can be written as :\n$$P(X=x) = {x+r-1 \\choose r-1}p^r(1-p)^x, \\quad x=0,1,2,3\\cdots \\infty$$\n\nNegative Binomial Distribution has :\n* mean $\\mu=\\frac{rq}{p}$ \n* vaiance $\\sigma^2=\\frac{rq}{p^2}$ \n* mgf $M_x(t)=\\frac{p^r}{(1-(1-p)e^t)^r}$",
      "metadata": {}
    },
    {
      "id": "51551b6a",
      "cell_type": "code",
      "source": "# Generate a random 1x10 distribution for probability 0.6\nnb = r.negative_binomial(n=10, p=0.4, size=10) ; nb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([13, 13, 18, 10, 26, 11, 21,  7, 14, 20])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 77
    },
    {
      "id": "67c1efad",
      "cell_type": "code",
      "source": "# Median of the distribution\n# median(n,p, loc=0)\n\nstats.nbinom.median(n=10, p=0.4)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14.0"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 78
    },
    {
      "id": "65653c44",
      "cell_type": "code",
      "source": "# Mean of the distribution.\n# mean(n, p, loc=0)\n\nstats.nbinom.mean(n=10, p=0.4)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15.0"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 79
    },
    {
      "id": "3b23466d",
      "cell_type": "code",
      "source": "# Variance of the distribution.\n# var(n, p, loc=0)\n\nstats.nbinom.var(n=10, p=0.4)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "37.5"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 80
    },
    {
      "id": "803b0bba",
      "cell_type": "code",
      "source": "# Mean(‘m’), variance(‘v’), skew(‘s’), \n# and/or kurtosis(‘k’).\n#stats(n, p, loc=0, moments=’mv’)\n\nstats.nbinom.stats(n=10, p=0.4, moments='mv')",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(15.), array(37.5))"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 81
    },
    {
      "id": "03650c6a",
      "cell_type": "markdown",
      "source": "* **Random variates : rvs(n, p, loc=0, size=1)**\n* **Probability mass function : pmf(x, n, p, loc=0)**\n\n**Q. An item is produced in large number. The machine is known to produce 5% defective items. A quality control inspector is examining the item by taking at random. What is the probability that atleast 4 items are to be examined in order to get 2 defectives.**\n\n**Ans. :** If 2 defective items to be obtained, then it can be happened in 2 or more trials. The probability of success at each trial is 0.05 . ",
      "metadata": {}
    },
    {
      "id": "c6773be9",
      "cell_type": "code",
      "source": "# P(X>=4) = 1-P(2<=X<=3)\nbin2 = 1-sum(stats.nbinom.pmf([2,3], n=4, p=0.05)) ; bin2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.999836421875"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 82
    },
    {
      "id": "19cc872b",
      "cell_type": "markdown",
      "source": "### Hypergeometric Distribution\nWe denote Hypergeometric Distribution as;\n<br> $X \\sim HPG(k; M, N, n)$\n\nSuppose a lot consisting of $N$ items of which $n$ of the items are defective $(N-n)$ of the items are non defective. If a sample of $n \\le N$ items are taken randomly without replacement and we define $X$ be the number of defective items in the sample.\n\nWe write the PMF of Hypergeometric Distribution as :\n$$P(X=x) =\\frac{{n \\choose k}{N-M \\choose n-k}}{{N \\choose n}}, k=0,1,2,3,…,min(n,M)$$\nwhere,  $x$ : represents the data set of values, $m$ : size of the population, $n$ : number of samples drawn, $k$ : number of items in the population, $N$ : hypergeometrically distributed values.\n\nIt has :\n* mean $\\mu=\\frac{nM}{N}$ \n* vaiance $\\sigma^2=\\frac{Mn}{N}\\frac{(M-1)(n-1)}{(N-1)}$",
      "metadata": {}
    },
    {
      "id": "f201e34d",
      "cell_type": "code",
      "source": "# Random Simulation \n[M,n,N]=[20,7,12]\nrhg = stats.hypergeom.rvs(M, n, N, size=10) ; rhg",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 3, 4, 6, 3, 4, 4, 6, 4, 3])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 83
    },
    {
      "id": "51b6bbe5",
      "cell_type": "code",
      "source": "# Median of the distribution : median(M, n, N, loc=0)\nstats.hypergeom.median(M, n, N)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 84
    },
    {
      "id": "0995f601",
      "cell_type": "code",
      "source": "# Mean of the distribution : mean(M, n, N, loc=0)\nstats.hypergeom.mean(M, n, N)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.199999999999999"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 85
    },
    {
      "id": "f2051abf",
      "cell_type": "code",
      "source": "# Variance of the distribution : var(M, n, N, loc=0)\nstats.hypergeom.var(M, n, N)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.1494736842105264"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 86
    },
    {
      "id": "847e1f5d",
      "cell_type": "code",
      "source": "# SD of the distribution : std(M, n, N, loc=0)\nstats.hypergeom.std(M, n, N)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0721351053904198"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 87
    },
    {
      "id": "dc620326",
      "cell_type": "code",
      "source": "# Mean(‘m’), variance(‘v’), skew(‘s’), \n# and/or kurtosis(‘k’).\n#stats(M,n,N, loc=0, moments=’mv’)\n\nstats.hypergeom.stats(M, n, N, moments='mv')",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(4.2), array(1.14947368))"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 88
    },
    {
      "id": "ad29553c",
      "cell_type": "code",
      "source": "# Cumulative distribution function : cdf(k, M, n, N, loc=0)\nstats.hypergeom.cdf(4, M, n, N) # k=4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6083591331269342"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 89
    },
    {
      "id": "b7187b18",
      "cell_type": "markdown",
      "source": "## Continuous Probability Distribution \n### Normal Distribution\nNormal(Gaussian / Gauss / Laplace-Gauss) is a type of continuous probability distribution for a real-valued random variable. \nThe normal distributions occurs often in nature. \n\nNormal distributions are important in statistics and are often used in the natural and social sciences to represent real-valued random variables whose distributions are not known.\n\nNormal Distribution is denoted as :\n<br> $X \\sim N(\\mu,\\sigma^2)$\n\nIt's PDF is denoted as:\n$$f_X(x)= \\frac{1}{\\sigma\\sqrt{2\\pi}}e^-\\frac{(x-\\mu)^2}{2\\sigma^2}, \\quad -\\infty<x<+\\infty, \\quad -\\infty<\\mu<+\\infty, \\quad \\sigma>0$$\nNormal Distribution has :\n* mean $\\mu$ \n* variance $\\sigma^2$ \n* mgf $M_x(t)=e^{\\mu t+\\frac{1}{2}\\sigma^2 t}$\n\n*The Normal pdf is also called as Bell Shape Curve.*\n\n**Properties :**\n* i. The curve is bell shaped and symmetric about $\\mu$.\n* ii. The *mean , median , mode*  of x consider at $\\mu$.\n* iii. If $X \\sim N(\\mu,\\sigma^2)$ then  $Z=\\frac{x-\\mu}{\\sigma} \\tilde \\quad N(0,1)$, this vaiate (Z) is *Standard Normal Variate* and it's pdf is $f_{x}(x)\\frac{1}{\\sqrt{2\\pi}}e^-{z^2/2},\\quad -\\infty<z<+\\infty$\n* iv. All the odd central moments are zero. i.e. $\\mu_{2r+1}=0,\\quad r=0,1,2,3,\\cdots$ and the even central moments are given by $\\mu_{2r=1.3.5......(2r-1)\\sigma^{2r}}$\n* v. Skewness $\\beta_1=0$ and $\\gamma_1=\\sqrt{\\beta_1}=0$\n* vi. Kurtosis $\\beta_2=3$ and $\\gamma_2=\\beta_2-3=0$\n* vii. Mean Deviation = $\\frac{4}{5}\\sigma$\n\n    * Quartile Deviation = $\\frac{2}{3}\\sigma$\n    * $QD:MD:SD::10:12:15$\n* viii. Area Property :\n\n    * a.$P(\\mu-\\sigma<X<\\mu+\\sigma) = 0.6826$\n    * b.$P(\\mu-2\\sigma<X<\\mu+2\\sigma) = 0.9544$\n    * c.$P(\\mu-3\\sigma<X<\\mu+3\\sigma) = 0.9973$\n* ix. $\\Phi_{(-z)} = 1-\\Phi_{(z)}$\n* x. $P(a \\le X \\le b) = \\Phi(\\frac{b-\\mu}{\\sigma})-\\Phi(\\frac{a-\\mu}{\\sigma})$",
      "metadata": {}
    },
    {
      "id": "a9b9a486",
      "cell_type": "code",
      "source": "# 10 Norml Random Sample of mean=3,sd=2\n[mean,sd,size] = [3,2,10]\nrnorm = np.random.normal(mean, sd, size) ;rnorm",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 2.86527657,  1.59177424, -3.4722086 ,  3.86667327,  6.09165961,\n",
              "        4.02195763,  2.4390429 ,  1.9798123 ,  4.46793209,  1.5162063 ])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 90
    },
    {
      "id": "5116bd81",
      "cell_type": "code",
      "source": "# Generate Random Number\nn1 = stats.norm.rvs(size=1000) ",
      "metadata": {},
      "outputs": [],
      "execution_count": 91
    },
    {
      "id": "35744bec",
      "cell_type": "code",
      "source": "# Probability Density Function(PDF)\nn2 = stats.norm.pdf(x=3) ; n2 # for x=3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0044318484119380075"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 92
    },
    {
      "id": "2577b3c4",
      "cell_type": "code",
      "source": "# Cumulative distribution function(CDF)\nn3 = stats.norm.cdf(x=3) ; n3 # for x=3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9986501019683699"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 93
    },
    {
      "id": "5710d81d",
      "cell_type": "code",
      "source": "# Non-central moment of order n\nstats.norm.moment(n=1000)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 94
    },
    {
      "id": "5ea01888",
      "cell_type": "code",
      "source": "stats.norm.moment(n=100)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.725392139750729e+78"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 95
    },
    {
      "id": "5e4d18a1",
      "cell_type": "code",
      "source": "# Mean(‘m’), variance(‘v’), skew(‘s’)\n# and/or kurtosis(‘k’)\n\nstats.norm.stats(2.22, moments='mv') # 2.22 is any random no.",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(2.22), array(1.))"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 96
    },
    {
      "id": "b4f66907",
      "cell_type": "code",
      "source": "# Median of the distribution\nstats.norm.median(3, 1000)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 97
    },
    {
      "id": "5298f6ec",
      "cell_type": "code",
      "source": "# Mean of the distribution\nstats.norm.mean(3, 1000)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 98
    },
    {
      "id": "ebe08f28",
      "cell_type": "code",
      "source": "# Variance of the distribution\nstats.norm.var(3, 1000)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000000.0"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 99
    },
    {
      "id": "ee79c96d",
      "cell_type": "code",
      "source": "# SD of the distribution\nstats.norm.std(3, 1000)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000.0"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 100
    },
    {
      "id": "df0f4336",
      "cell_type": "markdown",
      "source": "### Exponential Distribution\n*Poisson process :* A process in which events occur continuously and independently at a constant average rate.\n\nThe probability distribution of waiting time between events in a Poisson process is exponential distribution. The exponential distribution can be derived easily from Poisson distribution.\n\nWe denote the exponential distribution as :\n<br> $X \\sim exp(\\lambda)$\n\nWe denote the PDF of exponential distribution as : \n$$f_{x}(x)= \\lambda e^{-\\lambda x},\\quad x>0,\\lambda>0 \\Rightarrow F_{x}(x)=1-e^{-\\lambda x}$$\n\nExponential Distribution has \n* $mean = \\frac{1}{\\lambda}$ \n* $variance = \\frac{1}{\\lambda^2}$ \n* mgf $M_x(t) = \\frac{\\lambda}{(\\lambda-t)}$\n\n*Memortless Property of Exponential Distribution :*\n\nIf $T$ represents the lifetime of a given engine, then probability that engine will work at least $(s+t)$ hrs. given that it has already operated for $s$ hrs. is the same as the initial probability that the engine will function at least $t$ hrs. \n$$P(T>s+t|T>s)=\\frac{P(X>s+t)}{P(X>s)}=\\frac{e^{-\\lambda (s+t)}}{e^{-\\lambda s}}$$\nwhich implies $P(T>s+t|t>s)=e^{-\\lambda t}=P(T>t)$\n\n**Note :** *Exponential Distribution is only continuous distrgibution which has Memoryless property*",
      "metadata": {}
    },
    {
      "id": "9ad92af6",
      "cell_type": "code",
      "source": "# 10 Exponential Random Sample of mean=3\n[mean,size] = [3,10]\nrexp = np.random.exponential(mean, size) ;rexp",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.69081384, 0.3090427 , 0.95037508, 0.33085762, 1.59653581,\n",
              "       1.05486993, 7.4593103 , 0.77264828, 8.10084871, 2.27161349])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 101
    },
    {
      "id": "b739e26f",
      "cell_type": "code",
      "source": "e1 = stats.expon.rvs(size=1000)",
      "metadata": {},
      "outputs": [],
      "execution_count": 102
    },
    {
      "id": "719066e9",
      "cell_type": "code",
      "source": "# Probability density function\nstats.expon.pdf(x=3) # Pdf for x=3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.049787068367863944"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 103
    },
    {
      "id": "f87cb7ed",
      "cell_type": "code",
      "source": "# Cumulative distribution function\nstats.expon.cdf(x=3)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.950212931632136"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 104
    },
    {
      "id": "9b6cdd37",
      "cell_type": "code",
      "source": "# Non-central moment of order n\nstats.expon.moment(n=100)",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1790: IntegrationWarning: The algorithm does not converge.  Roundoff error is detected\n",
            "  in the extrapolation table.  It is assumed that the requested tolerance\n",
            "  cannot be achieved, and that the returned result (if full_output = 1) is \n",
            "  the best which can be obtained.\n",
            "  return integrate.quad(self._mom_integ1, 0, 1, args=(m,)+args)[0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.3861394261902593e+110"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 105
    },
    {
      "id": "1c023931",
      "cell_type": "code",
      "source": "e2 = stats.expon.rvs(size=10)\nstats.expon.stats(e2, moments='mv')",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([3.10069471, 3.73620088, 2.36510353, 3.01519899, 1.09429573,\n",
              "        1.24505219, 3.63460538, 4.68499052, 1.0251258 , 3.46430412]),\n",
              " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 106
    },
    {
      "id": "e5378b67",
      "cell_type": "code",
      "source": "# Median of the distribution\nstats.expon.median(e2)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.79384189, 3.42934806, 2.05825071, 2.70834617, 0.78744291,\n",
              "       0.93819937, 3.32775256, 4.3781377 , 0.71827298, 3.1574513 ])"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 107
    },
    {
      "id": "66b7fbc2",
      "cell_type": "code",
      "source": "# Mean of the distribution\nstats.expon.mean(e2)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3.10069471, 3.73620088, 2.36510353, 3.01519899, 1.09429573,\n",
              "       1.24505219, 3.63460538, 4.68499052, 1.0251258 , 3.46430412])"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 108
    },
    {
      "id": "71a9a27f",
      "cell_type": "code",
      "source": "# Variance of the distribution\nstats.expon.var(e2)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 109
    },
    {
      "id": "3a415a9c",
      "cell_type": "code",
      "source": "# SD of e1 by numpy\nnp.std(e1)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.98232942071236"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 110
    },
    {
      "id": "1575e28c",
      "cell_type": "code",
      "source": "# Mean of e1 by numpy\nnp.mean(e1)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9771791798004354"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 111
    },
    {
      "id": "e86b6347",
      "cell_type": "markdown",
      "source": "### Uniform Distribution\nWe denote the uniform distribution as :\n<br> $X \\sim U(a,b)$\n\nWe denote the pdf of Uniform Distribution as :\n$$f_x(x)=\\frac{1}{b-a},\\quad a\\le x \\le b \\Rightarrow F_x(x)=\\frac{x-a}{b-a},\\quad a\\le x \\le b$$\n\nUniform Distribution has \n* $mean = \\frac{b+a}{2}$ \n* $variance = \\frac{(b-a)^2}{12}$ \n* mgf $M_x(t) = \\frac{e^{bt}-e^{at}}{(b-a)t}$",
      "metadata": {}
    },
    {
      "id": "1aaa509e",
      "cell_type": "code",
      "source": "# 10 Uniform Random Sample from a=-10 , b=3\n[a,b,size] = [-10,3,10]\nrunif = np.random.uniform(a, b, size) ;runif",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-6.40407227, -9.07773792,  1.45847963, -0.80919345, -9.61372562,\n",
              "       -4.22240744,  0.88883501, -7.66706006, -2.30562083, -0.03057034])"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 112
    },
    {
      "id": "347bf01c",
      "cell_type": "code",
      "source": "# Random Variable between a=3 and b=5\nu1 = stats.uniform.rvs(3, 5, size=20) ; u1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5.81832125, 6.98328053, 5.89112159, 7.93792979, 3.93598355,\n",
              "       6.27771983, 4.82614108, 7.89126455, 5.59224537, 4.02718881,\n",
              "       5.67539821, 5.08547073, 5.06915321, 6.00304536, 4.11411339,\n",
              "       5.37042835, 4.24703317, 7.22334364, 3.412971  , 6.17896641])"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 113
    },
    {
      "id": "8ccf96c2",
      "cell_type": "code",
      "source": "# Mean ny numpy\nnp.mean(u1)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.578055991852663"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 114
    },
    {
      "id": "72c60ab3",
      "cell_type": "code",
      "source": "# Variance by numpy\nnp.var(u1)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.5806129962984008"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 115
    },
    {
      "id": "8124f96e",
      "cell_type": "code",
      "source": "# Probability density function\nstats.uniform.pdf(10)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 116
    },
    {
      "id": "097781cb",
      "cell_type": "code",
      "source": "# Cumulative distribution function\nstats.uniform.cdf(10)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 117
    },
    {
      "id": "98af32b0",
      "cell_type": "code",
      "source": "# Non-central moment of order n\nstats.uniform.moment(n=10)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.09090909090909093"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 118
    },
    {
      "id": "a3cc551e",
      "cell_type": "code",
      "source": "# Mean(‘m’), variance(‘v’), skew(‘s’)\n# and/or kurtosis(‘k’) \n# First Four Moments\n\nstats.uniform.stats(u1, moments='mvsk')",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([6.31832125, 7.48328053, 6.39112159, 8.43792979, 4.43598355,\n",
              "        6.77771983, 5.32614108, 8.39126455, 6.09224537, 4.52718881,\n",
              "        6.17539821, 5.58547073, 5.56915321, 6.50304536, 4.61411339,\n",
              "        5.87042835, 4.74703317, 7.72334364, 3.912971  , 6.67896641]),\n",
              " array([0.08333333, 0.08333333, 0.08333333, 0.08333333, 0.08333333,\n",
              "        0.08333333, 0.08333333, 0.08333333, 0.08333333, 0.08333333,\n",
              "        0.08333333, 0.08333333, 0.08333333, 0.08333333, 0.08333333,\n",
              "        0.08333333, 0.08333333, 0.08333333, 0.08333333, 0.08333333]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0.]),\n",
              " array([-1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2,\n",
              "        -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2, -1.2]))"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 119
    },
    {
      "id": "82697256",
      "cell_type": "markdown",
      "source": "### Gamma Distribution\nWe denote the Gamma Distribution as :\n<br> $X \\sim \\gamma(\\alpha,\\beta)$\n\nWe denote the pdf of Gamma Distribution as : \n$$f_{x}(x;\\alpha,\\beta)=\\frac{1}{\\Gamma_{(\\alpha)}\\beta^{\\alpha}}x^{\\alpha-1} e^{-x/\\beta},\\quad \\alpha>0,\\beta>0,0<x<\\infty$$\n\nGamma Distribution has :\n* $mean = \\alpha \\beta$ \n* $variance = \\alpha \\beta^2$ \n* mgf $M_x(t) = (\\frac{\\beta}{(\\beta-t)})^{\\alpha}$",
      "metadata": {}
    },
    {
      "id": "48ff9322",
      "cell_type": "code",
      "source": "# 10 Gamma Random Sample of scale 2.33 , shape=0.543\n[s,sg,size]=[2.33,0.543,10]\nrgamma=np.random.gamma(s,sg,size) ;rgamma",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.86968686, 0.72755513, 0.32744213, 0.51298527, 1.80628513,\n",
              "       0.26916618, 0.41528409, 1.44721757, 0.72332975, 0.52509941])"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 120
    },
    {
      "id": "ae51dbf4",
      "cell_type": "code",
      "source": "# Random Simulation \na = 1.99\ng1 = stats.gamma.rvs(a, size=1000)",
      "metadata": {},
      "outputs": [],
      "execution_count": 121
    },
    {
      "id": "b5292995",
      "cell_type": "code",
      "source": "# PDF for x=3\nstats.gamma.pdf(3, a)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1483503897331003"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 122
    },
    {
      "id": "bef19561",
      "cell_type": "code",
      "source": "# CDF for x=3\nstats.gamma.cdf(3, a)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.80282200386065"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 123
    },
    {
      "id": "c5107c53",
      "cell_type": "code",
      "source": "# Non-central moment of order n\nstats.gamma.moment(10, a)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39117523.35596883"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 124
    },
    {
      "id": "1cbce829",
      "cell_type": "code",
      "source": "# Mean(‘m’), variance(‘v’), skew(‘s’)\n# and/or kurtosis(‘k’)\n\nstats.gamma.stats(a)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(1.99), array(1.99))"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 125
    },
    {
      "id": "526be09f",
      "cell_type": "code",
      "source": "# Mean of a\nnp.mean(a)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.99"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 126
    },
    {
      "id": "7fcba497",
      "cell_type": "code",
      "source": "# Median of a\nnp.median(a)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.99"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 127
    },
    {
      "id": "3c3807aa",
      "cell_type": "code",
      "source": "# Variance of a \nstats.gamma.var(a)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.99"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 128
    },
    {
      "id": "02c38cbb",
      "cell_type": "markdown",
      "source": "### Beta Distribution\nWe denote the Beta Distribution as :\n<br> $X \\sim \\beta(\\mu, \\nu)$\n\nWe denote the PDF of Beta Distribution as :\n$$f_{x}(x)=\\frac{1}{\\beta(\\mu,\\nu)}x^{\\mu-1}(1-x)^{\\nu-1}, \\quad 0\\le x\\le 1, \\mu>0, \\nu>0$$ \nwhere, $\\beta(\\mu,\\nu)=\\frac{\\Gamma{\\mu}\\Gamma{\\nu}}{\\Gamma{(\\mu+\\nu)}}$\n\nBeta Distribution has :\n* $mean = \\frac{\\mu}{\\mu+\\nu}$ \n* $variance = \\frac{\\mu\\nu}{(\\mu+\\nu)^2(\\mu+\\nu+1)}$",
      "metadata": {}
    },
    {
      "id": "0cf8856a",
      "cell_type": "code",
      "source": "# 10 Beta Random Sample of sacle(sa)=3.22 , shape(sh)=0.543\n[sa,sh,size] = [3.22,0.543,10]\nrbeta=np.random.beta(sa, sh, size) ;rbeta",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.82359081, 0.95336603, 0.84772317, 0.47204414, 0.99249056,\n",
              "       0.9892374 , 0.98761979, 0.73801619, 0.9748022 , 0.84721256])"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 129
    },
    {
      "id": "0c05736d",
      "cell_type": "code",
      "source": "# Random Simulation\n[a,b]=[2.31, 0.627]\nbe1=stats.beta.rvs(a, b, size=10) ;be1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.94341202, 0.76214092, 0.86415896, 0.97770678, 0.67578132,\n",
              "       0.50764871, 0.9794141 , 0.98110907, 0.92642271, 0.4846018 ])"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 130
    },
    {
      "id": "e66a0b30",
      "cell_type": "code",
      "source": "# Mean by numpy\nnp.mean(be1)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8102396381205027"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 131
    },
    {
      "id": "39c417fb",
      "cell_type": "code",
      "source": "# Variance by numpy\nnp.var(be1)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.03379960905366268"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 132
    },
    {
      "id": "0eeda91f",
      "cell_type": "code",
      "source": "# PDF of Beta Distribution for x=5\nstats.beta.pdf(5, a, b)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 133
    },
    {
      "id": "8f40fba8",
      "cell_type": "code",
      "source": "# CDF of Beta Beta Distribution for x=5\nstats.beta.cdf(5, a, b)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 134
    },
    {
      "id": "a725d59b",
      "cell_type": "code",
      "source": "# first 4 moments\nstats.beta.stats(a, b, moments='mvsk')",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(0.78651685), array(0.04264874), array(-1.12407149), array(0.56545748))"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 135
    },
    {
      "id": "fb83cde4",
      "cell_type": "code",
      "source": "# Median using Scipy\nstats.beta.median(a, b)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.852865976189898"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 136
    },
    {
      "id": "fc2a3074",
      "cell_type": "code",
      "source": "# Mean using Scipy\nstats.beta.mean(a, b)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7865168539325842"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 137
    },
    {
      "id": "378b5fb9",
      "cell_type": "code",
      "source": "# Variance using Scipy\nstats.beta.var(a, b)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.04264874077027537"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 138
    },
    {
      "id": "2d8496f2",
      "cell_type": "code",
      "source": "# SD using Scipy\nstats.beta.std(a, b)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.20651571555277667"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 139
    },
    {
      "id": "38f3c8d2",
      "cell_type": "code",
      "source": "# Mean(‘m’), variance(‘v’), skew(‘s’)\n# and/or kurtosis(‘k’)\n\nstats.beta.stats(a, b, moments='mv')",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(0.78651685), array(0.04264874))"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 140
    },
    {
      "id": "cf99fb75",
      "cell_type": "markdown",
      "source": "### Log-Normal Distribution\nWe denote the Log-Normal Distribution as :\n<br> $Xlog\\sim N(\\mu,\\sigma^2)$\n\nWe denote the PDF of Log-Normal Distribution as :\n$$f_x(x)=\\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-\\frac{(lnx-\\mu)^2}{2\\sigma^2}}$$\n\nLog-Normal Distribution has \n* $mean = e^{\\mu+\\sigma^2/2}$ \n* $variance = (e^{\\sigma^2}-1)e^{2\\mu+\\sigma^2}$",
      "metadata": {}
    },
    {
      "id": "21e0c998",
      "cell_type": "code",
      "source": "# 10 log-Normal Random Sample of mean=3 , sd=2\n[ms,vs,size] = [3,2,10]\nrlogn = np.random.beta(ms, vs, size) ;rlogn",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.11394097, 0.79013872, 0.69374496, 0.43587752, 0.87127621,\n",
              "       0.66232794, 0.7525598 , 0.54663261, 0.24833714, 0.67031529])"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 141
    },
    {
      "id": "fbd7473e",
      "cell_type": "code",
      "source": "# Random Simulation \ns = 0.954\nln1 = stats.lognorm.rvs(s, size=10) ; ln1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.49036203, 1.74558191, 2.36170603, 1.78476642, 3.26998839,\n",
              "       0.61784083, 2.40683939, 1.42390597, 2.85237295, 1.89899708])"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 142
    },
    {
      "id": "34470e8d",
      "cell_type": "code",
      "source": "# Mean by numpy\nnp.mean(s)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.954"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 143
    },
    {
      "id": "938c3efd",
      "cell_type": "code",
      "source": "# Variance by numpy\nnp.var(s)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 144
    },
    {
      "id": "dd9d4425",
      "cell_type": "code",
      "source": "# Median by Scipy\nstats.lognorm.median(s)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 145
    },
    {
      "id": "11184dad",
      "cell_type": "code",
      "source": "# Mean by Scipy\nstats.lognorm.mean(s)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.576264803741382"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 146
    }
  ]
}